version: '3'
services:
  kafka:
    image: '{{ image_repository }}/public/kafka:2.13-2.7.0'
    network_mode: host
    extra_hosts:
      - '{{ hostvars[ansible_ssh_host].host_name }}:{{ ansible_ssh_host }}'
    restart: always
    environment:
      TZ: Asia/Shanghai
      #JMX_PORT: 9998
      #producer ack为all时，最少的同步个数(replica为3，insync为2,可以达到最大高可用)
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_COMPRESSION_TYPE: gzip
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_ADVERTISED_PORT: 9092
      DOCKER_API_VERSION: 1.22
      KAFKA_BROKER_ID: "{{ kafka_broker_id }}"
      KAFKA_ADVERTISED_HOST_NAME: "{{ ansible_ssh_host }}"
      KAFKA_ZOOKEEPER_CONNECT: '{{ zk_hosts_str }}'
      KAFKA_HEAP_OPTS: '{{ kafka_heap_opts }}'
      #5个logstash消费者,每个8个线程，40个partition
      KAFKA_NUM_PARTITIONS: 30
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://{{ ansible_ssh_host }}:9092
      #cpu核数+1
      KAFKA_NUM_NETWORK_THREADS: 9
      #cpu的两倍
      KAFKA_NUM_IO_THREADS: 16
      #partition*3=log文件个数90， 90/3=30 每台broker文件夹个数，每个segament默认1G，每个文件夹大小为(当前值+1)G,总大小不超过磁盘80%，2000G盘
      KAFKA_LOG_RETENTION_BYTES: 5368709120
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OPTS: -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent-0.12.0.jar=1234:/usr/share/jmx_exporter/kafka-broker.yml
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - "{{ kafka_root_dir }}/kafka:/kafka"
      - "{{ kafka_root_dir }}/logs:/opt/kafka/logs"
      - "{{ kafka_root_dir }}/jmx-exporter:/usr/share/jmx_exporter"
      - "/usr/share/zoneinfo/Asia/Shanghai:/usr/share/zoneinfo/Asia/Shanghai"